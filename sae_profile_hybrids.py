'''Script to compute hybrid scores for intermediate sequences.

For each intermediate sequence generated by the pathway search, this script
computes its sequence identity to the start and end sequences in the
FULL_CONTEXT_FILE alignment.
'''

import os
import sys
import json

import numpy as np
import torch
from pysam import FastaFile
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, EsmModel
from safetensors.torch import load_file
from interprot.sae_model import SparseAutoencoder
from huggingface_hub import hf_hub_download


# Ensure we can import from the project root when running as a script
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

from config.settings import (  # type: ignore  # noqa: E402
    FULL_CONTEXT_FILE,
    START_SEQ_NAME,
    END_SEQ_NAME,
    GENERATOR_OUTPUT_PATH,
    RANDOM_SEED,
)

# SAE model constants
ESM_DIM = 1280
SAE_DIM = 4096
LAYER = 24
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load SAE model once
print("Loading ESM and SAE models...")
# Load ESM model
tokenizer = AutoTokenizer.from_pretrained("facebook/esm2_t33_650M_UR50D")
esm_model = EsmModel.from_pretrained("facebook/esm2_t33_650M_UR50D")
esm_model.to(device)
esm_model.eval()

# Load SAE model
checkpoint_path = hf_hub_download(
    repo_id="liambai/InterProt-ESM2-SAEs",
    filename="esm2_plm1280_l24_sae4096.safetensors"
)
sae_model = SparseAutoencoder(ESM_DIM, SAE_DIM)
sae_model.load_state_dict(load_file(checkpoint_path))
sae_model.to(device)
sae_model.eval()
print("Models loaded successfully!") 

def filter_sae_latent_features(avg_source_latent_feature, top_k=500): 
    """
    Get positions of top k values in the latent feature array.
    
    Args:
        avg_source_latent_feature: numpy array (1D or 2D with shape 1, 4096)
        top_k: number of top features to return (default 500)
    
    Returns:
        numpy array of indices for the top k highest values
    """
    
    # Get indices of top k values (highest to lowest)
    # First filter by threshold, keeping track of original indices
    threshold_mask = avg_source_latent_feature > 0.1
    valid_indices = np.where(threshold_mask)[0]
    valid_values = avg_source_latent_feature[threshold_mask]
    
    # Sort the valid values and get top k
    sorted_indices = np.argsort(valid_values)[::-1][:top_k]
    # Map back to original indices
    top_k_features = valid_indices[sorted_indices]
    
    return top_k_features

def get_sae_latent_features(sequence_wo_gap):
    """Get latent features for a sequence using SAE"""
    
    inputs = tokenizer(sequence_wo_gap, padding=True, return_tensors="pt").to(device)

    # Get ESM embeddings
    with torch.no_grad():
        outputs = esm_model(**inputs, output_hidden_states=True)

    esm_layer_acts = outputs.hidden_states[LAYER][0]
    
    # Get SAE latent features
    with torch.no_grad():
        sae_latent_features = sae_model.get_acts(esm_layer_acts)
    
    # print(f"SAE latent features shape: {sae_latent_features.shape}")
    sae_latent_features = sae_latent_features.cpu().numpy() # L + 2, 4096
    
    # lets run added, average, and topk features
    avg_sae_latent_features   = np.mean(sae_latent_features, axis=0)

    return avg_sae_latent_features
    
def select_features_to_track(top_a, top_b, avg_source_latent_feature, avg_target_latent_feature, top_n=5):
    """
    Select features to track: common features with most variance, and unique features.
    
    Args:
        top_a: indices of top features in source
        top_b: indices of top features in target
        avg_source_latent_feature: actual feature values for source
        avg_target_latent_feature: actual feature values for target
        top_n: number of features to track in each category
    """
    set_b = set(top_b)
    set_a = set(top_a)
    
    # Find common features and sort by variance (absolute difference in values)
    common_features = [x for x in set_a if x in set_b]
    common_features.sort(key=lambda x: abs(avg_source_latent_feature[x] - avg_target_latent_feature[x]), reverse=True)
    common_features = common_features[:top_n]
    
    # Top features unique to each (not in the other's top list)
    only_source = [x for x in top_a if x not in set_b][:top_n]
    only_target = [y for y in top_b if y not in set_a][:top_n]
    return common_features, only_source, only_target

def get_sae_profile(avg_source_latent_feature: str, avg_target_latent_feature: str):
    

    top_500_source_features = filter_sae_latent_features(avg_source_latent_feature)
    top_500_target_features = filter_sae_latent_features(avg_target_latent_feature)

    common_features, only_source, only_target = select_features_to_track(top_500_source_features, top_500_target_features, avg_source_latent_feature, avg_target_latent_feature)
    return common_features, only_source, only_target


def calc_sae_profile() -> dict:
    # Load start and end sequences from the full MSA context
    print(f"Starting SAE (sparse auto encoder) profile calculation.")
    global_fasta = FastaFile(FULL_CONTEXT_FILE)
    starting_aln_sequence = global_fasta.fetch(START_SEQ_NAME)
    ending_aln_sequence   = global_fasta.fetch(END_SEQ_NAME)

    starting_sequence_wo_gap = starting_aln_sequence.replace("-", "")
    ending_sequence_wo_gap   = ending_aln_sequence.replace("-", "")

    avg_source_latent_feature = get_sae_latent_features(starting_sequence_wo_gap)
    avg_target_latent_feature = get_sae_latent_features(ending_sequence_wo_gap)
    
    common_features, source_only, target_only = get_sae_profile(avg_source_latent_feature, avg_target_latent_feature)
    print(f"Common features: {common_features}")
    print(f"Source only features: {source_only}")
    print(f"Target only features: {target_only}")

    # get source and target values
    source_common_feature_value = list(avg_source_latent_feature[common_features])
    source_only_feature_value = list(avg_source_latent_feature[source_only])
    source_target_only_feature_value = list(avg_source_latent_feature[target_only])

    target_common_feature_value = list(avg_target_latent_feature[common_features])
    target_source_only_feature_value = list(avg_target_latent_feature[source_only])
    target_only_feature_value = list(avg_target_latent_feature[target_only])

    target_common_change = (np.array(target_common_feature_value) - np.array(source_common_feature_value)) / np.array(source_common_feature_value) * 100.0
    target_source_only_change = (np.array(target_source_only_feature_value) - np.array(source_only_feature_value)) / np.array(source_only_feature_value) * 100.0
    target_target_only_change = (np.array(target_only_feature_value) - np.array(source_target_only_feature_value)) / np.array(source_target_only_feature_value) * 100.0

    target_change_concat = np.concatenate(
        [target_common_change, target_source_only_change, target_target_only_change]
    )   

    # Mean percent change values for the target sequence (for scatter plot reference)
    target_avg_source_only = float(np.mean(target_source_only_change))
    target_avg_target_only = float(np.mean(target_target_only_change))

    # Path to intermediate sequences produced by generate_pathway.py
    print(f"Processing Intermediate sequences from file: {GENERATOR_OUTPUT_PATH}")
    intermediate_sequences_file = os.path.join(
        GENERATOR_OUTPUT_PATH,
        f"beam_evol_msat_intermediate_seqs_{RANDOM_SEED}.fasta",
    )

    if not os.path.exists(intermediate_sequences_file):
        print(f"Intermediate FASTA not found: {intermediate_sequences_file}")
        return

    intermediates_fa = FastaFile(intermediate_sequences_file)
    intermediate_sequence_dict: dict[str, dict] = {}

    for int_seq_name in intermediates_fa.references:
        int_aln_sequence = intermediates_fa.fetch(int_seq_name)
        int_sequence_wo_gap = int_aln_sequence.replace("-", "")
        avg_int_latent_feature = get_sae_latent_features(int_sequence_wo_gap)

        int_common_feature_value = list(avg_int_latent_feature[common_features])
        int_source_only_feature_value = list(avg_int_latent_feature[source_only])
        int_target_only_feature_value = list(avg_int_latent_feature[target_only])

        # get the percentage change to the source
        int_common_feature_value = np.array(int_common_feature_value)
        source_common_feature_value = np.array(source_common_feature_value)
        
        int_source_only_feature_value = np.array(int_source_only_feature_value)
        source_only_feature_value = np.array(source_only_feature_value)
        
        int_target_only_feature_value = np.array(int_target_only_feature_value)
        source_target_only_feature_value = np.array(source_target_only_feature_value)
        
        int_common_feature_value_change = (int_common_feature_value - source_common_feature_value) / source_common_feature_value
        int_source_only_feature_value_change = (int_source_only_feature_value - source_only_feature_value) / source_only_feature_value
        int_target_only_feature_value_change = (int_target_only_feature_value - source_target_only_feature_value) / source_target_only_feature_value

        intermediate_sequence_dict[int_seq_name] = {
          "source_common_feature_value": source_common_feature_value.tolist(),
          "source_only_feature_value": source_only_feature_value.tolist(),
          "source_target_only_feature_value": source_target_only_feature_value.tolist(),
          
          # target_* values are Python lists already; ensure list type without .tolist()
          "target_common_feature_value": list(target_common_feature_value),
          "target_source_only_feature_value": list(target_source_only_feature_value),
          "target_only_feature_value": list(target_only_feature_value),

          "int_common_feature_value": int_common_feature_value.tolist(),
          "int_source_only_feature_value": int_source_only_feature_value.tolist(),
          "int_target_only_feature_value": int_target_only_feature_value.tolist(),

          "int_common_feature_value_change": (int_common_feature_value_change * 100).tolist(),
          "int_source_only_feature_value_change": (int_source_only_feature_value_change * 100).tolist(),
          "int_target_only_feature_value_change": (int_target_only_feature_value_change * 100).tolist(),

        }

    # save
    out_json = os.path.join(GENERATOR_OUTPUT_PATH, f"hybrids_sae_profile_{RANDOM_SEED}.json")

    def _json_default(o):
        # Safely convert NumPy scalar types to native Python types
        if isinstance(o, (np.floating,)):
            return float(o)
        return str(o)

    with open(out_json, "w") as f:
        json.dump(intermediate_sequence_dict, f, default=_json_default)

    print(f"SAE profile calculation completed. Saved to {out_json}")
    return intermediate_sequence_dict, target_change_concat, target_avg_source_only, target_avg_target_only

def plot_sae_profile() -> None:
    """Scatter: min_seq_similarity (x) vs min_str_similarity (y), colored by hybrid_score."""
    sae_profile, target_change_concat, target_avg_source_only, target_avg_target_only = calc_sae_profile()

    # Collect per-feature percentage changes across all intermediates
    common_changes = []   # shape: (n_intermediates, 5)
    source_only_changes = []  # shape: (n_intermediates, 5)
    target_only_changes = []  # shape: (n_intermediates, 5)

    for _, s in sae_profile.items():
        common_changes.append(np.asarray(s["int_common_feature_value_change"], dtype=float))
        source_only_changes.append(np.asarray(s["int_source_only_feature_value_change"], dtype=float))
        target_only_changes.append(np.asarray(s["int_target_only_feature_value_change"], dtype=float))

    if not common_changes:
        print("No SAE profile entries to plot.")
        return

    common_changes = np.vstack(common_changes)       # (n, 5)
    source_only_changes = np.vstack(source_only_changes)  # (n, 5)
    target_only_changes = np.vstack(target_only_changes)  # (n, 5)

    # Prepare data for a single 15-column boxplot
    boxplot_data = []
    labels = []

    for i in range(common_changes.shape[1]):
        boxplot_data.append(common_changes[:, i])
        labels.append(f"C{i+1}")

    for i in range(source_only_changes.shape[1]):
        boxplot_data.append(source_only_changes[:, i])
        labels.append(f"S{i+1}")

    for i in range(target_only_changes.shape[1]):
        boxplot_data.append(target_only_changes[:, i])
        labels.append(f"T{i+1}")

    plt.figure(figsize=(12, 6))
    plt.boxplot(boxplot_data, tick_labels=labels, showfliers=False)

    # Overlay red line segments showing where the target sequence sits for each feature
    positions = np.arange(1, len(labels) + 1)
    for idx, val in enumerate(target_change_concat):
        plt.hlines(
            y=val,
            xmin=positions[idx] - 0.2,
            xmax=positions[idx] + 0.2,
            colors="red",
            linestyles="--",
            linewidth=1.2,
            label="Target sequence" if idx == 0 else None,
        )

    plt.ylabel("Percent change from source (%)")
    plt.xlabel("SAE feature (C: common, S: source-only, T: target-only)")
    plt.title("Distribution of SAE latent feature percent changes across intermediates")
    plt.legend()
    plt.tight_layout()

    out_path = os.path.join(
        GENERATOR_OUTPUT_PATH,
        f"hybrids_sae_profile_boxplot_{RANDOM_SEED}.png",
    )
    plt.savefig(out_path, dpi=300)
    plt.close()
    print(f"Saved SAE profile boxplot to {out_path}")
    
    # Second plot: single scatter of avg source-only vs avg target-only percent change per intermediate
    avg_source_only = np.mean(source_only_changes, axis=1)
    avg_target_only = np.mean(target_only_changes, axis=1)

    plt.figure(figsize=(6, 6))
    # Intermediates
    plt.scatter(avg_source_only, avg_target_only, alpha=0.7, label="Intermediates")
    # Target sequence reference point
    plt.scatter(
        target_avg_source_only,
        target_avg_target_only,
        color="red",
        marker="*",
        s=120,
        label="Target sequence",
        zorder=3,
    )
    # Optional reference line y = x
    min_val = min(avg_source_only.min(), avg_target_only.min(), target_avg_source_only, target_avg_target_only)
    max_val = max(avg_source_only.max(), avg_target_only.max(), target_avg_source_only, target_avg_target_only)
    plt.plot([min_val, max_val], [min_val, max_val], "k--", linewidth=1)
    plt.xlabel("Mean percent change of source-only features (%)")
    plt.ylabel("Mean percent change of target-only features (%)")
    plt.title("SAE latent feature percentage change per intermediate")
    plt.legend()
    plt.tight_layout()

    out_path2 = os.path.join(
        GENERATOR_OUTPUT_PATH,
        f"hybrids_sae_profile_scatterplot_{RANDOM_SEED}.png",
    )
    plt.savefig(out_path2, dpi=300)
    plt.close()
    print(f"Saved average source/target-only change plot to {out_path2}")


if __name__ == "__main__":
    plot_sae_profile()
